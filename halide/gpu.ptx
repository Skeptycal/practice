Injecting tracing...
Injecting profiling...
Adding checks for parameters
Computing bounds of each function's value
Adding checks for images
Performing computation bounds inference...
Performing sliding window optimization...
Performing allocation bounds inference...
Uniquifying variable names...
Performing storage folding optimization...
Injecting debug_to_file calls...
Simplifying...
Dynamically skipping stages...
Performing storage flattening...
Removing code that depends on undef values...
Simplifying...
Unrolling...
Simplifying...
Vectorizing...
Simplifying...
Specializing clamped ramps...
Detecting vector interleavings...
Injecting early frees...
Simplifying...
Simplified: 
let gradient_gpu.extent.0.required = (min((((((gradient_gpu.extent.0 + -1)/4)*4) + gradient_gpu.min.0) + 4), (gradient_gpu.min.0 + gradient_gpu.extent.0)) - min(gradient_gpu.min.0, ((gradient_gpu.min.0 + gradient_gpu.extent.0) + -4)))
let gradient_gpu.min.0.required = min(gradient_gpu.min.0, ((gradient_gpu.min.0 + gradient_gpu.extent.0) + -4))
let gradient_gpu.extent.1.required = (min((((((gradient_gpu.extent.1 + -1)/4)*4) + gradient_gpu.min.1) + 4), (gradient_gpu.min.1 + gradient_gpu.extent.1)) - min(gradient_gpu.min.1, ((gradient_gpu.min.1 + gradient_gpu.extent.1) + -4)))
let gradient_gpu.min.1.required = min(gradient_gpu.min.1, ((gradient_gpu.min.1 + gradient_gpu.extent.1) + -4))
if (gradient_gpu.host_and_dev_are_null) {
  rewrite_buffer(gradient_gpu.buffer, 4, gradient_gpu.min.0.required, gradient_gpu.extent.0.required, 1, gradient_gpu.min.1.required, gradient_gpu.extent.1.required, gradient_gpu.extent.0.required)
}
if (!gradient_gpu.host_and_dev_are_null) {
  assert((gradient_gpu.elem_size == 4), "Output buffer gradient_gpu has type float32, but elem_size of the buffer_t passed in is %d instead of 4", gradient_gpu.elem_size)
  assert((gradient_gpu.min.0 <= gradient_gpu.min.0.required), "Output buffer gradient_gpu is accessed at %d, which is before the min (%d) in dimension 0", gradient_gpu.min.0.required, gradient_gpu.min.0)
  assert((((gradient_gpu.min.0.required + gradient_gpu.extent.0.required) - gradient_gpu.extent.0) <= gradient_gpu.min.0), "Output buffer gradient_gpu is accessed at %d, which is beyond the max (%d) in dimension 0", ((gradient_gpu.min.0.required + gradient_gpu.extent.0.required) + -1), ((gradient_gpu.min.0 + gradient_gpu.extent.0) + -1))
  assert((gradient_gpu.min.1 <= gradient_gpu.min.1.required), "Output buffer gradient_gpu is accessed at %d, which is before the min (%d) in dimension 1", gradient_gpu.min.1.required, gradient_gpu.min.1)
  assert((((gradient_gpu.min.1.required + gradient_gpu.extent.1.required) - gradient_gpu.extent.1) <= gradient_gpu.min.1), "Output buffer gradient_gpu is accessed at %d, which is beyond the max (%d) in dimension 1", ((gradient_gpu.min.1.required + gradient_gpu.extent.1.required) + -1), ((gradient_gpu.min.1 + gradient_gpu.extent.1) + -1))
  assert((gradient_gpu.stride.0 == 1), "Static constraint violated: gradient_gpu.stride.0 == 1")
  let gradient_gpu.total_extent.0 = int64(gradient_gpu.extent.0)
  let gradient_gpu.total_extent.1.s = int64(gradient_gpu.extent.1)
  assert((gradient_gpu.total_extent.0 <= int64(2147483647)), "Total allocation for buffer gradient_gpu exceeds 2^31 - 1")
  assert(((gradient_gpu.total_extent.1.s*int64(gradient_gpu.stride.1)) <= int64(2147483647)), "Total allocation for buffer gradient_gpu exceeds 2^31 - 1")
  assert(((gradient_gpu.total_extent.1.s*gradient_gpu.total_extent.0) <= int64(2147483647)), "Product of extents for buffer gradient_gpu exceeds 2^31 - 1")
  produce gradient_gpu {
    parallel (gradient_gpu.s0.y.blockidy, 0, ((gradient_gpu.extent.1 + 3)/4)) {
      let gradient_gpu.s0.y.threadidy.base = min(((gradient_gpu.s0.y.blockidy*4) + gradient_gpu.min.1), ((gradient_gpu.min.1 + gradient_gpu.extent.1) + -4))
      parallel (gradient_gpu.s0.x.blockidx, 0, ((gradient_gpu.extent.0 + 3)/4)) {
        let gradient_gpu.s0.x.threadidx.base = min(((gradient_gpu.s0.x.blockidx*4) + gradient_gpu.min.0), ((gradient_gpu.min.0 + gradient_gpu.extent.0) + -4))
        parallel (gradient_gpu.s0.y.threadidy, 0, 4) {
          parallel (gradient_gpu.s0.x.threadidx, 0, 4) {
            gradient_gpu[(((gradient_gpu.s0.x.threadidx.base + gradient_gpu.s0.x.threadidx) - gradient_gpu.min.0) + (((gradient_gpu.s0.y.threadidy.base + gradient_gpu.s0.y.threadidy) - gradient_gpu.min.1)*gradient_gpu.stride.1))] = ((float32((gradient_gpu.s0.x.threadidx.base + gradient_gpu.s0.x.threadidx))*float32((gradient_gpu.s0.y.threadidy.base + gradient_gpu.s0.y.threadidy))) + 42.195000f)
          }
        }
      }
    }
  }
  0
}


Constructing CUDA device codegen
Target triple of initial module: x86_64-unknown-unknown-unknown
Target triple of initial module: x86_64--linux-gnu
Generating llvm bitcode...
Generating llvm bitcode for kernel...
PTX kernel:
//
// Generated by LLVM NVPTX Back-End
//

.version 3.1
.target sm_20, texmode_independent
.address_size 64

	// .globl	kernel_gradient_gpu_s0_y_blockidy
                                        // @kernel_gradient_gpu_s0_y_blockidy
.entry kernel_gradient_gpu_s0_y_blockidy(
	.param .u32 kernel_gradient_gpu_s0_y_blockidy_param_0,
	.param .u32 kernel_gradient_gpu_s0_y_blockidy_param_1,
	.param .u32 kernel_gradient_gpu_s0_y_blockidy_param_2,
	.param .u32 kernel_gradient_gpu_s0_y_blockidy_param_3,
	.param .u32 kernel_gradient_gpu_s0_y_blockidy_param_4,
	.param .u64 .ptr .align 1 kernel_gradient_gpu_s0_y_blockidy_param_5
)
{
	.reg .pred %p<396>;
	.reg .s16 %rc<396>;
	.reg .s16 %rs<396>;
	.reg .s32 %r<396>;
	.reg .s64 %rl<396>;
	.reg .f32 %f<396>;
	.reg .f64 %fl<396>;

// BB#0:                                // %entry
	mov.u32 	%r3, %ctaid.y;
	ld.param.u32 	%r2, [kernel_gradient_gpu_s0_y_blockidy_param_1];
	add.s32 	%r0, %r2, 3;
	shr.s32 	%r0, %r0, 2;
	setp.ge.s32 	%p0, %r3, %r0;
	@%p0 bra 	BB0_2;
// BB#1:                                // %gradient_gpu.s0.y.blockidy_loop
	ld.param.u32 	%r4, [kernel_gradient_gpu_s0_y_blockidy_param_0];
	mov.u32 	%r5, %ctaid.x;
	add.s32 	%r0, %r4, 3;
	shr.s32 	%r0, %r0, 2;
	setp.lt.s32 	%p0, %r5, %r0;
	@%p0 bra 	BB0_3;
	bra.uni 	BB0_2;
BB0_3:                                  // %gradient_gpu.s0.x.blockidx_loop
	mov.u32 	%r0, %tid.y;
	setp.gt.s32 	%p0, %r0, 3;
	@%p0 bra 	BB0_2;
// BB#4:                                // %gradient_gpu.s0.y.threadidy_loop
	mov.u32 	%r1, %tid.x;
	setp.gt.s32 	%p0, %r1, 3;
	@%p0 bra 	BB0_2;
// BB#5:                                // %gradient_gpu.s0.x.threadidx_loop
	ld.param.u32 	%r6, [kernel_gradient_gpu_s0_y_blockidy_param_2];
	ld.param.u32 	%r7, [kernel_gradient_gpu_s0_y_blockidy_param_3];
	ld.param.u32 	%r8, [kernel_gradient_gpu_s0_y_blockidy_param_4];
	ld.param.u64 	%rl0, [kernel_gradient_gpu_s0_y_blockidy_param_5];
	shl.b32 	%r3, %r3, 2;
	add.s32 	%r3, %r3, %r7;
	add.s32 	%r2, %r2, %r7;
	add.s32 	%r2, %r2, -4;
	setp.lt.s32 	%p0, %r3, %r2;
	selp.b32 	%r2, %r3, %r2, %p0;
	shl.b32 	%r3, %r5, 2;
	add.s32 	%r3, %r3, %r6;
	add.s32 	%r4, %r4, %r6;
	add.s32 	%r4, %r4, -4;
	setp.lt.s32 	%p0, %r3, %r4;
	selp.b32 	%r3, %r3, %r4, %p0;
	add.s32 	%r4, %r0, %r2;
	cvt.rn.f32.s32 	%f0, %r4;
	add.s32 	%r4, %r1, %r3;
	cvt.rn.f32.s32 	%f1, %r4;
	fma.rn.f32 	%f0, %f0, %f1, 0f4228C7AE;
	cvt.s64.s32 	%rl1, %r8;
	cvt.s64.s32 	%rl2, %r7;
	cvt.s64.s32 	%rl3, %r0;
	cvt.s64.s32 	%rl4, %r2;
	sub.s64 	%rl2, %rl4, %rl2;
	add.s64 	%rl2, %rl2, %rl3;
	cvt.s64.s32 	%rl4, %r6;
	cvt.s64.s32 	%rl3, %r1;
	cvt.s64.s32 	%rl5, %r3;
	sub.s64 	%rl4, %rl5, %rl4;
	mad.lo.s64 	%rl1, %rl2, %rl1, %rl4;
	add.s64 	%rl1, %rl1, %rl3;
	shl.b64 	%rl1, %rl1, 2;
	add.s64 	%rl0, %rl0, %rl1;
	st.f32 	[%rl0], %f0;
	ret;
BB0_2:                                  // %gradient_gpu.s0.y.blockidy_after_loop
	ret;
}


Looking for cuda shared library...
User error triggered at src/CodeGen_GPU_Host.cpp:519
Condition failed: error.empty()
Error:
Could not find libcuda.so, libcuda.dylib, or nvcuda.dll
